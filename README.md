# Medical Video Projects Resources

* [Foundation Model for Endoscopy Video Analysis](https://github.com/openmedlab/Endo-FM)
* [A multimodal video dataset of human spermatozoa](https://www.kaggle.com/datasets/stevenhicks/visem-video-dataset)


## Instructional Medical Videos
### [A dataset for medical instructional video classification and question answering](https://www.nature.com/articles/s41597-023-02036-y)
* [MedVidQACL](https://github.com/deepaknlp/MedVidQACL)
  
### [How Well Can General Vision-Language Models Learn Medicine By Watching Public Educational Videos?](https://arxiv.org/abs/2504.14391)
* [OpenBiomedVid](https://github.com/zou-group/OpenBiomedVid)
* [SurgeryVideoQA](https://huggingface.co/datasets/connectthapa84/SurgeryVideoQA)
* [MIMIC-IV-ECHO: Echocardiogram Matched Subset](https://physionet.org/content/mimic-iv-echo/0.1/)
  
## [Echonet datasets and models](https://github.com/echonet)
* [EchonNet-LVH: A Large Parasternal Long Axis Echocardiography Video Dataset, Model, and  Paper](https://echonet.github.io/lvh/)
* [EchoNet-Pediatric: A Large Pediatric Echocardiography Video Dataset, Model, and Paper](https://echonet.github.io/pediatric/index.html)
* [EchoNet-Dynamic: Interpretable AI for beat-to-beat cardiac function assessment Dataset, Model, and Paper](https://github.com/echonet/dynamic)
* [EchoNet: Tee-View-Classifier datasets and paper](https://aimi.stanford.edu/datasets/echonet-tee-view-classifier) and [model](https://github.com/echonet/tee-view-classifier)

## Others
* [Endora: Video Generation Models as Endoscopy Simulators](https://endora-medvidgen.github.io/)
  
## Medical video-related datasets
* [A public endoscopic video dataset for polyp detection](https://github.com/dashishi/LDPolypVideo-Benchmark)
* [Carotid Ultrasound Boundary Study (CUBS): Technical considerations on an open multi-center analysis of computerized measurement systems for intima-media thickness measurement on common carotid artery longitudinal B-mode ultrasound scans](https://data.mendeley.com/datasets/m7ndn58sv6/1)
  
## [PyTorch video](https://pytorchvideo.org/)
* [Models documentation](https://pytorchvideo.readthedocs.io/en/latest/models.html)
* [Models on GitHub](https://github.com/facebookresearch/pytorchvideo/tree/main/pytorchvideo/models/hub)
* [Pretrained models on specific datasets and performance](https://github.com/facebookresearch/pytorchvideo/blob/main/docs/source/model_zoo.md)
* [Build your own model tutorial](https://pytorchvideo.org/docs/tutorial_accelerator_build_your_model#introduction)

## Select Tensorflow models for video and multimodal risk assessment
* [DISIML models: Echo, ECG, tabular data models, and autoencoders for dimensionality reduction](https://alvarouc.gitlab.io/disiml/)
  
## Select PyTorch video classification models
* [Vision ResNet model](https://docs.pytorch.org/vision/stable/models/video_resnet.html)
* [3D ResNet](https://pytorch.org/hub/facebookresearch_pytorchvideo_resnet/)
* [X3D: Expanding Architectures for Efficient Video Recognition](https://pytorch.org/hub/facebookresearch_pytorchvideo_x3d/)
* [SlowFast Networks for Video Recognition](https://pytorch.org/hub/facebookresearch_pytorchvideo_slowfast/)
* [MViTv2: Improved Multiscale Vision Transformers for Classification and Detection](https://docs.pytorch.org/vision/main/models/video_mvit.html)
* [Video Swin Transformer model](https://docs.pytorch.org/vision/stable/models/video_swin_transformer.html)

## [SAM2 foundation model](https://ai.meta.com/sam2/)
* [SAM2 foundation model for video](https://github.com/facebookresearch/sam2)
* [SAM2 paper](https://ai.meta.com/research/publications/sam-2-segment-anything-in-images-and-videos/)

## PyTorch video documentation
* [Video datasets](https://docs.pytorch.org/vision/main/datasets.html#video-classification)
* [Optical Flow datasets for video motion estimation](https://docs.pytorch.org/vision/main/datasets.html#optical-flow)

## Guidelines for training models
* [Model training information](https://github.com/pattichis/AIMV/blob/main/opt.md)


